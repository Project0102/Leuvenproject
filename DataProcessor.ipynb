{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress warning printouts\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils import threshold_interactions_df\n",
    "from scipy import sparse\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the AlbumId info from albumData1.txt\n",
    "data_albumId = []\n",
    "with open('../ydata1/albumData1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('|')\n",
    "        data_albumId.append(fields)\n",
    "df_album = pd.DataFrame(data_albumId)\n",
    "df_album.columns = ['AlbumId','ArtistId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId']\n",
    "num_rows_album = len(df_album)\n",
    "#print(df_album.info())\n",
    "\n",
    "# Read the first column (ArtistId) from artistData1.txt\n",
    "df_artist = pd.read_csv('../ydata1/artistData1.txt', delimiter='|', header=None, names=['ArtistId'])\n",
    "num_rows_artist = len(df_artist)\n",
    "#print(df_artist.info())\n",
    "\n",
    "# Read the first column (GenreId) from genreData1.txt\n",
    "df_genre = pd.read_csv('../ydata1/genreData1.txt', delimiter='|', header=None, names=['GenreId'])\n",
    "num_rows_genre = len(df_genre)\n",
    "#print(df_genre.info())\n",
    "\n",
    "# Read the TrackId info from trackData.txt\n",
    "data_trackId = []\n",
    "with open('../ydata1/trackData1.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('|')\n",
    "        data_trackId.append(fields)\n",
    "df_track = pd.DataFrame(data_trackId)\n",
    "df_track.columns = ['TrackId','AlbumId','ArtistId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId','GenreId']\n",
    "num_rows_track = len(df_track)\n",
    "#print(df_track.info())\n",
    "\n",
    "# Calculate the total sum of the number of rows for all the files\n",
    "total_sum = num_rows_track + num_rows_album + num_rows_artist + num_rows_genre\n",
    "print(f\"Total sum of the number of items for all files: {total_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_track = pd.read_csv('../ydata1/filtered_data_track_50.csv')\n",
    "data_genre = pd.read_csv('../ydata1/filtered_data_genre_50.csv')\n",
    "data_genre.rename(columns={'item_id': 'genre_id'}, inplace=True)\n",
    "data_artist = pd.read_csv('../ydata1/filtered_data_artist_50.csv')\n",
    "data_artist.rename(columns={'item_id': 'artist_id'}, inplace=True)\n",
    "#print(data_track.info())\n",
    "#print(data_genre.info())\n",
    "#print(data_artist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User count: \", data_track['user_id'].nunique())\n",
    "print(\"Last user value: \", data_track['user_id'].iloc[-1])\n",
    "print(\"Item count: \", data_track['item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(data_track['user_id']) == set(data_genre['user_id']) == set(data_artist['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_id_counts = data_track['user_id'].value_counts()\n",
    "print(\"Length of user_id interactions with count more than 50:\", len(x_id_counts[x_id_counts >= 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_id_counts = data_track['item_id'].value_counts()\n",
    "print(\"Length of item_id interactions with count more than 50:\", len(x_id_counts[x_id_counts >= 50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_track = threshold_interactions_df(data_track,'user_id','item_id',50,50)\n",
    "filtered_data_track.reset_index(drop=True, inplace=True)\n",
    "filtered_data_track.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"User count: \", filtered_data_track['user_id'].nunique())\n",
    "print(\"Last user value: \", filtered_data_track['user_id'].iloc[-1])\n",
    "print(\"Item count: \", filtered_data_track['item_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common user_id values\n",
    "common_user_ids = set(filtered_data_track['user_id']) & set(data_genre['user_id']) & set(data_artist['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter each dataframe based on common user_id values\n",
    "filtered_data_genre = data_genre[data_genre['user_id'].isin(common_user_ids)]\n",
    "filtered_data_genre.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_genre.info())\n",
    "print(\"User count: \", filtered_data_genre['user_id'].nunique())\n",
    "print(\"Last user value: \", filtered_data_genre['user_id'].iloc[-1])\n",
    "print(\"Item count: \", filtered_data_genre['genre_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter each dataframe based on common user_id values\n",
    "filtered_data_artist = data_artist[data_artist['user_id'].isin(common_user_ids)]\n",
    "filtered_data_artist.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_artist.info())\n",
    "print(\"User count: \", filtered_data_artist['user_id'].nunique())\n",
    "print(\"Last user value: \", filtered_data_artist['user_id'].iloc[-1])\n",
    "print(\"Item count: \", filtered_data_artist['artist_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find common user_id values\n",
    "set(filtered_data_track['user_id']) == set(filtered_data_genre['user_id']) == set(filtered_data_artist['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between unique user_id values and their corresponding factorization labels\n",
    "#print(len(filtered_data_track['user_id'].unique()))\n",
    "#print(len(filtered_data_genre['user_id'].unique()))\n",
    "#print(len(filtered_data_artist['user_id'].unique()))\n",
    "unique_user_ids = pd.concat([filtered_data_track['user_id'], filtered_data_genre['user_id'], filtered_data_artist['user_id']]).unique()\n",
    "print (len(unique_user_ids))\n",
    "factorization_labels = range(0, len(unique_user_ids))\n",
    "mapping = dict(zip(unique_user_ids, factorization_labels))\n",
    "#print(mapping)\n",
    "# Update the user_id columns in both DataFrames using the mapping\n",
    "filtered_data_track['user_id'] = filtered_data_track['user_id'].map(mapping)\n",
    "filtered_data_genre['user_id'] = filtered_data_genre['user_id'].map(mapping)\n",
    "filtered_data_artist['user_id'] = filtered_data_artist['user_id'].map(mapping)\n",
    "filtered_data_track.reset_index(drop=True, inplace=True)\n",
    "filtered_data_genre.reset_index(drop=True, inplace=True)\n",
    "filtered_data_artist.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_track.info())\n",
    "#print(filtered_data_genre.info())\n",
    "#print(filtered_data_artist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_track['TrackId'] = df_track['TrackId'].astype('int64')\n",
    "df_track_subset = df_track[df_track['TrackId'].isin(filtered_data_track['item_id'])]\n",
    "df_track_subset.reset_index(drop=True, inplace=True)\n",
    "#df_track_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary\n",
    "track_genre_dict = {}\n",
    "# Iterate over the DataFrame rows\n",
    "for index, row in df_track_subset.iterrows():\n",
    "    # Get the TrackId and artistId values from the row\n",
    "    track_id = int(row['TrackId'])\n",
    "    genre_ids = [int(genre_id) for genre_id in row['GenreId'] if genre_id is not None]\n",
    "    # Add the non-empty artistId values to the dictionary\n",
    "    if track_id not in track_genre_dict:\n",
    "        track_genre_dict[track_id] = genre_ids\n",
    "    else:\n",
    "        track_genre_dict[track_id].extend(genre_ids)\n",
    "print(len(track_genre_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_values = []\n",
    "for value_list in track_genre_dict.values():\n",
    "    all_values.extend(value_list)\n",
    "all_values = (set(all_values))\n",
    "len(all_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_filtered_data_genre = filtered_data_genre[filtered_data_genre['genre_id'].isin(set(all_values))]\n",
    "f_filtered_data_genre.reset_index(drop=True, inplace=True)\n",
    "#filtered_data_genre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data_genre['genre_id'].nunique())\n",
    "print(f_filtered_data_genre['genre_id'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group and count ratings by genre_id\n",
    "genre_counts = f_filtered_data_genre.groupby('genre_id')['rating'].count()\n",
    "# Step 2: Sort the counts in descending order\n",
    "sorted_counts = genre_counts.sort_values(ascending=False)\n",
    "# Step 3: Select the top 50 genres\n",
    "top_50_genres = sorted_counts.head(168)\n",
    "# Print the top 50 genres and their ratings count\n",
    "print(len(set(top_50_genres.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Group and count ratings by item_id\n",
    "item_counts = filtered_data_track.groupby('item_id')['rating'].count()\n",
    "# Step 2: Sort the counts in descending order\n",
    "sorted_counts = item_counts.sort_values(ascending=False)\n",
    "# Step 3: Select the top 50 items\n",
    "top_50_items = sorted_counts.head(5754)\n",
    "print(type(top_50_items))\n",
    "# Print the top 50 items and their ratings count\n",
    "print(len(set(top_50_items.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store the item_ids covered in top_50_genres and the genre_ids covered in top_50_items\n",
    "item_ids_in_top_genres = []\n",
    "genre_ids_in_top_items = []\n",
    "for item_id in set(top_50_items.index):\n",
    "    if item_id in track_genre_dict.keys():\n",
    "        for genre_id in track_genre_dict[item_id]:\n",
    "            # Check if any genre_id in the genre_ids list is in top_50_items\n",
    "            if genre_id in top_50_genres.index:\n",
    "                genre_ids_in_top_items.append(genre_id)\n",
    "                item_ids_in_top_genres.append(item_id)\n",
    "    else:\n",
    "        print(\"FALSE\")\n",
    "print(len(set(item_ids_in_top_genres)))\n",
    "print(len(set(genre_ids_in_top_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(genre_ids_in_top_items)))\n",
    "print(len(set(top_50_genres.index)))\n",
    "print(len(set(genre_ids_in_top_items)) - len(set(top_50_genres.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set(item_ids_in_top_genres)))\n",
    "print(len(set(top_50_items.index)))\n",
    "print(len(set(item_ids_in_top_genres)) - len(set(top_50_items.index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_data_track['item_id'].nunique())\n",
    "print(len(set(item_ids_in_top_genres)))\n",
    "print(filtered_data_genre['genre_id'].nunique())\n",
    "print(len(set(genre_ids_in_top_items)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between item_id and their corresponding factorization labels\n",
    "unique_item_ids = filtered_data_track['item_id'].unique()\n",
    "print (len(unique_item_ids))\n",
    "factorization_item_labels = range(0, len(unique_item_ids))\n",
    "mapping = dict(zip(unique_item_ids, factorization_item_labels))\n",
    "# Update the item_id columns using the mapping\n",
    "filtered_data_track['item_id'] = filtered_data_track['item_id'].map(mapping)\n",
    "filtered_data_track.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_track.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the updated list\n",
    "updated_item_ids_in_top_genres = []\n",
    "\n",
    "# Update each item_id in the list using the mapping dictionary\n",
    "for item_id in set(item_ids_in_top_genres):\n",
    "    updated_item_ids_in_top_genres.append(mapping.get(item_id, item_id))\n",
    "\n",
    "# Use the updated list as needed\n",
    "print(len(sorted(updated_item_ids_in_top_genres)))\n",
    "#print(sorted(updated_item_ids_in_top_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(all(item in filtered_data_track['item_id'].unique() for item in updated_item_ids_in_top_genres))\n",
    "#print(all(item in updated_item_ids_in_top_genres for item in filtered_data_track['item_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_genre = filtered_data_genre[filtered_data_genre['genre_id'].isin(set(genre_ids_in_top_items))]\n",
    "filtered_data_genre.reset_index(drop=True, inplace=True)\n",
    "print(filtered_data_genre['genre_id'].nunique())\n",
    "#filtered_data_genre.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between item_id and their corresponding factorization labels\n",
    "unique_item_ids = filtered_data_genre['genre_id'].unique()\n",
    "print (len(unique_item_ids))\n",
    "factorization_item_labels = range(0, len(unique_item_ids))\n",
    "mapping = dict(zip(unique_item_ids, factorization_item_labels))\n",
    "# Update the genre_id columns using the mapping\n",
    "filtered_data_genre['genre_id'] = filtered_data_genre['genre_id'].map(mapping)\n",
    "filtered_data_genre.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_genre.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the updated list\n",
    "updated_genre_ids_in_top_items = []\n",
    "\n",
    "# Update each item_id in the list using the mapping dictionary\n",
    "for genre_id in set(genre_ids_in_top_items):\n",
    "    updated_genre_ids_in_top_items.append(mapping.get(genre_id, genre_id))\n",
    "\n",
    "# Use the updated list as needed\n",
    "print(len(sorted(updated_genre_ids_in_top_items)))\n",
    "#print(sorted(updated_item_ids_in_top_genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all(item in filtered_data_genre['genre_id'].unique() for item in updated_genre_ids_in_top_items))\n",
    "print(all(item in updated_genre_ids_in_top_items for item in filtered_data_genre['genre_id'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping between item_id and their corresponding factorization labels\n",
    "unique_item_ids = filtered_data_artist['artist_id'].unique()\n",
    "print (len(unique_item_ids))\n",
    "factorization_item_labels = range(0, len(unique_item_ids))\n",
    "mapping = dict(zip(unique_item_ids, factorization_item_labels))\n",
    "# Update the artist_id columns using the mapping\n",
    "filtered_data_artist['artist_id'] = filtered_data_artist['artist_id'].map(mapping)\n",
    "filtered_data_artist.reset_index(drop=True, inplace=True)\n",
    "#print(filtered_data_artist.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(filtered_data_track['user_id']) == set(filtered_data_genre['user_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data_genre.to_csv('data/filtered_data_genre.csv', index = False)\n",
    "filtered_data_artist.to_csv('data/filtered_data_artist.csv', index = False)\n",
    "filtered_data_track.to_csv('data/filtered_data_track.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/top_items.pkl\", \"wb\") as file:\n",
    "    pickle.dump(updated_item_ids_in_top_genres, file)\n",
    "with open(\"data/top_genres.pkl\", \"wb\") as file:\n",
    "    pickle.dump(updated_genre_ids_in_top_items, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anndl",
   "language": "python",
   "name": "anndl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
